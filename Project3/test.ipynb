{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8578efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import xgboost as xgb \n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import re \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ff5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorizer(vocab_file):\n",
    "    corpus = None\n",
    "    with open(vocab_file, encoding='UTF-8') as f:\n",
    "        corpus = f.readlines() \n",
    "    corpus = [w.strip() for w in corpus]\n",
    "    voca = dict()\n",
    "    for idx, term in enumerate(corpus):\n",
    "        voca[term] = idx\n",
    "\n",
    "    vectorizer = CountVectorizer(vocabulary=voca, ngram_range=(1, 10))\n",
    "    return vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196cd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dirc = 'D:\\\\studying\\\\UIUC courses\\\\STAT542\\\\project\\\\Project3\\\\splits\\\\split_{}\\\\'\n",
    "cleaner = re.compile('<.*?>') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb7d593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = r'D:\\studying\\UIUC courses\\STAT542\\project\\Project3\\splits\\vocab_lasso_10_999.txt'\n",
    "# vocab_file = 'D:\\\\studying\\\\UIUC courses\\\\STAT542\\\\project\\\\Project3\\\\splits\\\\vocab_lasso_840.txt'\n",
    "vectorizer = get_vectorizer(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a970e241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a993c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: 1\n",
      "auc: 0.9588617088651888\n",
      "running time: 73.72855758666992\n",
      "split: 2\n",
      "auc: 0.9586232726109628\n",
      "running time: 73.30441880226135\n",
      "split: 3\n",
      "auc: 0.9579323132304199\n",
      "running time: 73.77296924591064\n",
      "split: 4\n",
      "auc: 0.958935231318548\n",
      "running time: 74.2836103439331\n",
      "split: 5\n",
      "auc: 0.9579574162223122\n",
      "running time: 74.13735008239746\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    start = time.time()\n",
    "    print('split: ' + str(i))\n",
    "    dirc = split_dirc.format(i)\n",
    "\n",
    "    train_file = dirc + 'train.tsv'\n",
    "    test_file = dirc + 'test.tsv'\n",
    "    test_y_file = dirc + 'test_y.tsv'\n",
    "    \n",
    "    train = pd.read_csv(train_file, sep='\\t', encoding='utf-8')\n",
    "    train['review'] = train['review'].map(lambda s: re.sub(cleaner, '', s))\n",
    "\n",
    "    test = pd.read_csv(test_file, sep='\\t', encoding='utf-8')\n",
    "    test['review'] = test['review'].map(lambda s: re.sub(cleaner, '', s))\n",
    "\n",
    "    test_y = pd.read_csv(test_y_file, sep='\\t', encoding='utf-8')\n",
    "\n",
    "    X_train = vectorizer.transform(train['review'].values).toarray()\n",
    "    X_train = pd.DataFrame(X_train, columns=vectorizer.get_feature_names())\n",
    "    Y_train = train['sentiment']\n",
    "\n",
    "    X_test = vectorizer.transform(test['review'].values).toarray()\n",
    "    X_test = pd.DataFrame(X_test, columns=vectorizer.get_feature_names())\n",
    "\n",
    "    ridge = LogisticRegression(C=0.5, random_state=2021, max_iter=1000)\n",
    "    ridge.fit(X_train, Y_train)\n",
    "\n",
    "    true_y = test_y['sentiment'].values\n",
    "\n",
    "    pred_test = ridge.predict_proba(X_test)\n",
    "\n",
    "    auc = roc_auc_score(true_y, pred_test[:,1])\n",
    "    end = time.time()\n",
    "    print('auc:', auc)\n",
    "    print('running time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b29601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_auc = []\n",
    "all_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7f88f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: 1\n",
      "auc: 0.9588617088651888\n",
      "running time: 73.98\n",
      "split: 2\n",
      "auc: 0.9586232726109628\n",
      "running time: 73.1\n",
      "split: 3\n",
      "auc: 0.9579323132304199\n",
      "running time: 73.53\n",
      "split: 4\n",
      "auc: 0.958935231318548\n",
      "running time: 73.74\n",
      "split: 5\n",
      "auc: 0.9579574162223122\n",
      "running time: 74.02\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    start = time.time()\n",
    "    print('split: ' + str(i))\n",
    "    dirc = split_dirc.format(i)\n",
    "\n",
    "    train_file = dirc + 'train.tsv'\n",
    "    test_file = dirc + 'test.tsv'\n",
    "    test_y_file = dirc + 'test_y.tsv'\n",
    "    \n",
    "    train = pd.read_csv(train_file, sep='\\t', encoding='utf-8')\n",
    "    train['review'] = train['review'].map(lambda s: re.sub(cleaner, '', s))\n",
    "\n",
    "    test = pd.read_csv(test_file, sep='\\t', encoding='utf-8')\n",
    "    test['review'] = test['review'].map(lambda s: re.sub(cleaner, '', s))\n",
    "    pred_id = test['id']\n",
    "\n",
    "    test_y = pd.read_csv(test_y_file, sep='\\t', encoding='utf-8')\n",
    "\n",
    "    X_train = vectorizer.transform(train['review'].values).toarray()\n",
    "    X_train = pd.DataFrame(X_train, columns=vectorizer.get_feature_names())\n",
    "    Y_train = train['sentiment']\n",
    "\n",
    "    X_test = vectorizer.transform(test['review'].values).toarray()\n",
    "    X_test = pd.DataFrame(X_test, columns=vectorizer.get_feature_names())\n",
    "\n",
    "    ridge = LogisticRegression(C=0.5, random_state=2021, max_iter=1000)\n",
    "    ridge.fit(X_train, Y_train)\n",
    "\n",
    "    true_y = test_y['sentiment'].values\n",
    "\n",
    "    pred_test = ridge.predict_proba(X_test)\n",
    "\n",
    "    auc = roc_auc_score(true_y, pred_test[:,1])\n",
    "    end = time.time()\n",
    "    t = np.round(end - start, 2)\n",
    "    all_auc.append(auc)\n",
    "    all_time.append(t)\n",
    "    print('auc:', auc)\n",
    "    print('running time:', t)\n",
    "    sub = dirc + 'mysubmission.txt'\n",
    "    mysubmission = pd.DataFrame({'id': pred_id, 'prob': pred_test[:, 1]})\n",
    "    mysubmission.to_csv(sub, sep='\\t', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfbb677b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9588617088651888,\n",
       " 0.9586232726109628,\n",
       " 0.9579323132304199,\n",
       " 0.958935231318548,\n",
       " 0.9579574162223122]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ffb20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[73.98, 73.1, 73.53, 73.74, 74.02]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.coef_.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd30cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f5a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'feature': vectorizer.get_feature_names(), 'coef': ridge.coef_.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d701d2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>not recommend</td>\n",
       "      <td>-1.793241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>not worth</td>\n",
       "      <td>-1.768052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>mst3k</td>\n",
       "      <td>-1.641706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>uninspired</td>\n",
       "      <td>-1.519235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>redeeming</td>\n",
       "      <td>-1.504856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>funniest</td>\n",
       "      <td>1.294789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>underrated</td>\n",
       "      <td>1.327980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>well worth</td>\n",
       "      <td>1.518508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>definitely worth</td>\n",
       "      <td>1.640683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>refreshing</td>\n",
       "      <td>1.922206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              feature      coef\n",
       "686     not recommend -1.793241\n",
       "501         not worth -1.768052\n",
       "643             mst3k -1.641706\n",
       "601        uninspired -1.519235\n",
       "472         redeeming -1.504856\n",
       "..                ...       ...\n",
       "151          funniest  1.294789\n",
       "64         underrated  1.327980\n",
       "28         well worth  1.518508\n",
       "83   definitely worth  1.640683\n",
       "92         refreshing  1.922206\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.sort_values(by=['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8321c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\studying\\\\UIUC courses\\\\STAT542\\\\project\\\\Project3\\\\splits\\\\split_{}\\\\'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dirc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e9669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.to_csv('D:\\\\studying\\\\UIUC courses\\\\STAT542\\\\project\\\\Project3\\\\splits\\\\coef.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9dc968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
