{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92bf456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8578efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import xgboost as xgb \n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import re \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ff5e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorizer(vocab_file):\n",
    "    corpus = None\n",
    "    with open(vocab_file, encoding='UTF-8') as f:\n",
    "        corpus = f.readlines() \n",
    "    corpus = [w.strip() for w in corpus]\n",
    "    voca = dict()\n",
    "    for idx, term in enumerate(corpus):\n",
    "        voca[term] = idx\n",
    "\n",
    "    vectorizer = CountVectorizer(vocabulary=voca, ngram_range=(1, 10))\n",
    "    return vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196cd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dirc = 'D:\\\\studying\\\\UIUC courses\\\\STAT542\\\\project\\\\Project3\\\\splits\\\\split_{}\\\\'\n",
    "cleaner = re.compile('<.*?>') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb7d593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = r'D:\\studying\\UIUC courses\\STAT542\\project\\Project3\\splits\\vocab_lasso_10_999.txt'\n",
    "# vocab_file = 'D:\\\\studying\\\\UIUC courses\\\\STAT542\\\\project\\\\Project3\\\\splits\\\\vocab_lasso_840.txt'\n",
    "vectorizer = get_vectorizer(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a970e241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a1447",
   "metadata": {},
   "source": [
    "# tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cb20bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c86734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirc = split_dirc.format(i)\n",
    "\n",
    "train_file = dirc + 'train.tsv'\n",
    "test_file = dirc + 'test.tsv'\n",
    "test_y_file = dirc + 'test_y.tsv'\n",
    "\n",
    "train = pd.read_csv(train_file, sep='\\t', encoding='utf-8')\n",
    "train['review'] = train['review'].map(lambda s: re.sub(cleaner, '', s))\n",
    "\n",
    "test = pd.read_csv(test_file, sep='\\t', encoding='utf-8')\n",
    "test['review'] = test['review'].map(lambda s: re.sub(cleaner, '', s))\n",
    "\n",
    "test_y = pd.read_csv(test_y_file, sep='\\t', encoding='utf-8')\n",
    "\n",
    "X_train = vectorizer.transform(train['review'].values).toarray()\n",
    "# X_train = pd.DataFrame(X_train, columns=vectorizer.get_feature_names())\n",
    "Y_train = train['sentiment']\n",
    "\n",
    "X_test = vectorizer.transform(test['review'].values).toarray()\n",
    "# X_test = pd.DataFrame(X_test, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb15b7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c2d94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=vectorizer.get_feature_names())\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=vectorizer.get_feature_names())\n",
    "\n",
    "true_y = test_y['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33b8450e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 auc: 0.9598295085805553\n",
      "0.0002 auc: 0.9611261226300377\n",
      "0.0003 auc: 0.9615697278997224\n",
      "0.0004 auc: 0.9617467655257093\n",
      "0.0005 auc: 0.9618114634275639\n",
      "0.0006 auc: 0.9618199242670388\n",
      "0.0007 auc: 0.9618015945815197\n",
      "0.0008 auc: 0.9617628744008669\n",
      "0.0009 auc: 0.9617145925756031\n",
      "0.001 auc: 0.9616640323397093\n"
     ]
    }
   ],
   "source": [
    "for c in np.linspace(0.0001, 0.001, 10):\n",
    "    c = np.round(c, 4)\n",
    "    print(c, end=' ')\n",
    "    ridge = LogisticRegression(C=c, random_state=2021, max_iter=1000, penalty='l2', solver='liblinear')\n",
    "    ridge.fit(X_train, Y_train)\n",
    "\n",
    "    pred_test = ridge.predict_proba(X_test)\n",
    "\n",
    "    auc = roc_auc_score(true_y, pred_test[:,1])\n",
    "    print('auc:', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70bab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6251a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f083da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = LogisticRegression(C=0.5, random_state=2021, max_iter=1000)\n",
    "ridge.fit(X_train, Y_train)\n",
    "\n",
    "true_y = test_y['sentiment'].values\n",
    "\n",
    "pred_test = ridge.predict_proba(X_test)\n",
    "\n",
    "auc = roc_auc_score(true_y, pred_test[:,1])\n",
    "print('auc:', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b87ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97012ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad8b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576126bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd961850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a993c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: 1\n",
      "auc: 0.9588617088651888\n",
      "running time: 73.72855758666992\n",
      "split: 2\n",
      "auc: 0.9586232726109628\n",
      "running time: 73.30441880226135\n",
      "split: 3\n",
      "auc: 0.9579323132304199\n",
      "running time: 73.77296924591064\n",
      "split: 4\n",
      "auc: 0.958935231318548\n",
      "running time: 74.2836103439331\n",
      "split: 5\n",
      "auc: 0.9579574162223122\n",
      "running time: 74.13735008239746\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    start = time.time()\n",
    "    print('split: ' + str(i))\n",
    "    dirc = split_dirc.format(i)\n",
    "\n",
    "    train_file = dirc + 'train.tsv'\n",
    "    test_file = dirc + 'test.tsv'\n",
    "    test_y_file = dirc + 'test_y.tsv'\n",
    "    \n",
    "    train = pd.read_csv(train_file, sep='\\t', encoding='utf-8')\n",
    "    train['review'] = train['review'].map(lambda s: re.sub(cleaner, '', s))\n",
    "\n",
    "    test = pd.read_csv(test_file, sep='\\t', encoding='utf-8')\n",
    "    test['review'] = test['review'].map(lambda s: re.sub(cleaner, '', s))\n",
    "\n",
    "    test_y = pd.read_csv(test_y_file, sep='\\t', encoding='utf-8')\n",
    "\n",
    "    X_train = vectorizer.transform(train['review'].values).toarray()\n",
    "    # X_train = pd.DataFrame(X_train, columns=vectorizer.get_feature_names())\n",
    "    Y_train = train['sentiment']\n",
    "\n",
    "    X_test = vectorizer.transform(test['review'].values).toarray()\n",
    "    # X_test = pd.DataFrame(X_test, columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    scaler = StandardScaler() \n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=vectorizer.get_feature_names())\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns=vectorizer.get_feature_names())\n",
    "\n",
    "    ridge = LogisticRegression(C=0.5, random_state=2021, max_iter=1000)\n",
    "    ridge.fit(X_train, Y_train)\n",
    "\n",
    "    true_y = test_y['sentiment'].values\n",
    "\n",
    "    pred_test = ridge.predict_proba(X_test)\n",
    "\n",
    "    auc = roc_auc_score(true_y, pred_test[:,1])\n",
    "    end = time.time()\n",
    "    print('auc:', auc)\n",
    "    print('running time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0330bdb",
   "metadata": {},
   "source": [
    "# 5 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b29601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_auc = []\n",
    "all_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b7f88f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: 1\n",
      "auc: 0.9618845965687738\n",
      "running time: 69.95\n",
      "split: 2\n",
      "auc: 0.9606171850221539\n",
      "running time: 70.08\n",
      "split: 3\n",
      "auc: 0.9607445590221857\n",
      "running time: 70.02\n",
      "split: 4\n",
      "auc: 0.9608431941396443\n",
      "running time: 70.06\n",
      "split: 5\n",
      "auc: 0.9601191260251195\n",
      "running time: 70.06\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    start = time.time()\n",
    "    print('split: ' + str(i))\n",
    "    dirc = split_dirc.format(i)\n",
    "\n",
    "    train_file = dirc + 'train.tsv'\n",
    "    test_file = dirc + 'test.tsv'\n",
    "    test_y_file = dirc + 'test_y.tsv'\n",
    "    \n",
    "    train = pd.read_csv(train_file, sep='\\t', encoding='utf-8')\n",
    "    train['review'] = train['review'].map(lambda s: re.sub(cleaner, '', s))\n",
    "\n",
    "    test = pd.read_csv(test_file, sep='\\t', encoding='utf-8')\n",
    "    test['review'] = test['review'].map(lambda s: re.sub(cleaner, '', s))\n",
    "    pred_id = test['id']\n",
    "\n",
    "    test_y = pd.read_csv(test_y_file, sep='\\t', encoding='utf-8')\n",
    "\n",
    "    X_train = vectorizer.transform(train['review'].values).toarray()\n",
    "    # X_train = pd.DataFrame(X_train, columns=vectorizer.get_feature_names())\n",
    "    Y_train = train['sentiment']\n",
    "\n",
    "    X_test = vectorizer.transform(test['review'].values).toarray()\n",
    "    # X_test = pd.DataFrame(X_test, columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    scaler = StandardScaler() \n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=vectorizer.get_feature_names())\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns=vectorizer.get_feature_names())\n",
    "\n",
    "    ridge = LogisticRegression(C=0.0007, random_state=2021, max_iter=1000)\n",
    "    ridge.fit(X_train, Y_train)\n",
    "\n",
    "    true_y = test_y['sentiment'].values\n",
    "\n",
    "    pred_test = ridge.predict_proba(X_test)\n",
    "\n",
    "    auc = roc_auc_score(true_y, pred_test[:,1])\n",
    "    end = time.time()\n",
    "    t = np.round(end - start, 2)\n",
    "    all_auc.append(auc)\n",
    "    all_time.append(t)\n",
    "    print('auc:', auc)\n",
    "    print('running time:', t)\n",
    "    sub = dirc + 'mysubmission.txt'\n",
    "    mysubmission = pd.DataFrame({'id': pred_id, 'prob': pred_test[:, 1]})\n",
    "    mysubmission.to_csv(sub, sep='\\t', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfbb677b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9618845965687738,\n",
       " 0.9606171850221539,\n",
       " 0.9607445590221857,\n",
       " 0.9608431941396443,\n",
       " 0.9601191260251195]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99ffb20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69.95, 70.08, 70.02, 70.06, 70.06]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.coef_.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd30cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5f5a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'feature': vectorizer.get_feature_names(), 'coef': ridge.coef_.reshape(-1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d701d2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>worst</td>\n",
       "      <td>-0.197746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>awful</td>\n",
       "      <td>-0.174627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>bad</td>\n",
       "      <td>-0.148358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>waste</td>\n",
       "      <td>-0.142396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>poor</td>\n",
       "      <td>-0.134137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>0.107991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.119839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent</td>\n",
       "      <td>0.151538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best</td>\n",
       "      <td>0.160606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great</td>\n",
       "      <td>0.194965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature      coef\n",
       "422      worst -0.197746\n",
       "424      awful -0.174627\n",
       "421        bad -0.148358\n",
       "423      waste -0.142396\n",
       "432       poor -0.134137\n",
       "..         ...       ...\n",
       "2    wonderful  0.107991\n",
       "5      perfect  0.119839\n",
       "1    excellent  0.151538\n",
       "3         best  0.160606\n",
       "0        great  0.194965\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.sort_values(by=['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8321c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\studying\\\\UIUC courses\\\\STAT542\\\\project\\\\Project3\\\\splits\\\\split_{}\\\\'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dirc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36e9669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df.to_csv('D:\\\\studying\\\\UIUC courses\\\\STAT542\\\\project\\\\Project3\\\\splits\\\\coef.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9dc968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
